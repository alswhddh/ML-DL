{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "train = pd.read_csv(\"./kaggle/train.csv\")\n",
    "label = train['income']\n",
    "\n",
    "del train['income']\n",
    "\n",
    "test = pd.read_csv(\"./kaggle/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨값 인코딩 현재 50 이상 50미만 기호로 되어있음 0과 1로 변환\n",
    "label = label.map(lambda x: 1 if x == '>50K' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#필요없는 컬럼 삭제\n",
    "del train['id']\n",
    "del test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#원본데이터는 보존\n",
    "tmp_train = train.copy()\n",
    "tmp_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6378</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>177675</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16583</th>\n",
       "      <td>49</td>\n",
       "      <td>Private</td>\n",
       "      <td>40666</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10591</th>\n",
       "      <td>24</td>\n",
       "      <td>Private</td>\n",
       "      <td>92609</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21539</th>\n",
       "      <td>22</td>\n",
       "      <td>?</td>\n",
       "      <td>210802</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18666</th>\n",
       "      <td>58</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>129786</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16354</th>\n",
       "      <td>34</td>\n",
       "      <td>Private</td>\n",
       "      <td>40067</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14182</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>43945</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16222</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>241895</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22703</th>\n",
       "      <td>29</td>\n",
       "      <td>Private</td>\n",
       "      <td>320451</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Philippines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6484</th>\n",
       "      <td>50</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>100480</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age    workclass  fnlwgt     education  education_num  \\\n",
       "6378    32      Private  177675       HS-grad              9   \n",
       "16583   49      Private   40666  Some-college             10   \n",
       "10591   24      Private   92609     Bachelors             13   \n",
       "21539   22            ?  210802  Some-college             10   \n",
       "18666   58  Federal-gov  129786          10th              6   \n",
       "...    ...          ...     ...           ...            ...   \n",
       "16354   34      Private   40067  Some-college             10   \n",
       "14182   41      Private   43945       7th-8th              4   \n",
       "16222   40      Private  241895  Some-college             10   \n",
       "22703   29      Private  320451       HS-grad              9   \n",
       "6484    50    Local-gov  100480       Masters             14   \n",
       "\n",
       "           marital_status       occupation   relationship                race  \\\n",
       "6378        Never-married     Craft-repair      Own-child               White   \n",
       "16583  Married-civ-spouse  Farming-fishing        Husband               White   \n",
       "10591       Never-married  Exec-managerial      Own-child               White   \n",
       "21539       Never-married                ?  Not-in-family               Black   \n",
       "18666  Married-civ-spouse     Craft-repair        Husband               White   \n",
       "...                   ...              ...            ...                 ...   \n",
       "16354  Married-civ-spouse     Craft-repair        Husband               White   \n",
       "14182  Married-civ-spouse     Craft-repair        Husband               White   \n",
       "16222  Married-civ-spouse     Adm-clerical        Husband               White   \n",
       "22703       Never-married  Protective-serv  Not-in-family  Asian-Pac-Islander   \n",
       "6484   Married-civ-spouse  Exec-managerial        Husband               White   \n",
       "\n",
       "          sex  capital_gain  capital_loss  hours_per_week native_country  \n",
       "6378     Male             0             0              40  United-States  \n",
       "16583    Male             0             0              50  United-States  \n",
       "10591    Male             0             0              45  United-States  \n",
       "21539  Female             0             0              35  United-States  \n",
       "18666    Male             0             0              40  United-States  \n",
       "...       ...           ...           ...             ...            ...  \n",
       "16354    Male             0             0              40  United-States  \n",
       "14182    Male             0             0              40              ?  \n",
       "16222    Male             0             0              40  United-States  \n",
       "22703    Male             0             0              40    Philippines  \n",
       "6484     Male             0             0              60  United-States  \n",
       "\n",
       "[200 rows x 14 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_train.sample(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26049 entries, 0 to 26048\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             26049 non-null  int64 \n",
      " 1   workclass       26049 non-null  object\n",
      " 2   fnlwgt          26049 non-null  int64 \n",
      " 3   education       26049 non-null  object\n",
      " 4   education_num   26049 non-null  int64 \n",
      " 5   marital_status  26049 non-null  object\n",
      " 6   occupation      26049 non-null  object\n",
      " 7   relationship    26049 non-null  object\n",
      " 8   race            26049 non-null  object\n",
      " 9   sex             26049 non-null  object\n",
      " 10  capital_gain    26049 non-null  int64 \n",
      " 11  capital_loss    26049 non-null  int64 \n",
      " 12  hours_per_week  26049 non-null  int64 \n",
      " 13  native_country  26049 non-null  object\n",
      "dtypes: int64(6), object(8)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# 결측치 확인\n",
    "tmp_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education_num</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26049.000000</td>\n",
       "      <td>2.604900e+04</td>\n",
       "      <td>26049.000000</td>\n",
       "      <td>26049.00000</td>\n",
       "      <td>26049.000000</td>\n",
       "      <td>26049.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.569235</td>\n",
       "      <td>1.903045e+05</td>\n",
       "      <td>10.088372</td>\n",
       "      <td>1087.68970</td>\n",
       "      <td>87.732734</td>\n",
       "      <td>40.443126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.671489</td>\n",
       "      <td>1.059663e+05</td>\n",
       "      <td>2.567610</td>\n",
       "      <td>7388.85469</td>\n",
       "      <td>403.230205</td>\n",
       "      <td>12.361850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.376900e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.181080e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.788660e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.377350e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.484705e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.00000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  education_num  capital_gain  capital_loss  \\\n",
       "count  26049.000000  2.604900e+04   26049.000000   26049.00000  26049.000000   \n",
       "mean      38.569235  1.903045e+05      10.088372    1087.68970     87.732734   \n",
       "std       13.671489  1.059663e+05       2.567610    7388.85469    403.230205   \n",
       "min       17.000000  1.376900e+04       1.000000       0.00000      0.000000   \n",
       "25%       28.000000  1.181080e+05       9.000000       0.00000      0.000000   \n",
       "50%       37.000000  1.788660e+05      10.000000       0.00000      0.000000   \n",
       "75%       48.000000  2.377350e+05      12.000000       0.00000      0.000000   \n",
       "max       90.000000  1.484705e+06      16.000000   99999.00000   4356.000000   \n",
       "\n",
       "       hours_per_week  \n",
       "count    26049.000000  \n",
       "mean        40.443126  \n",
       "std         12.361850  \n",
       "min          1.000000  \n",
       "25%         40.000000  \n",
       "50%         40.000000  \n",
       "75%         45.000000  \n",
       "max         99.000000  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#통계수치 확인\n",
    "tmp_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결측치 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "? 로 된 결측치가  'workclass', 'occupation', 'native_country' 칼럼에 존재함\n",
    "이 결측치들을 처리해 줘야함.\n",
    "\n",
    "이 데이터들은 범주형 변수이기 떄문에 가장 간단하게 최빈값으로 결측치를 처리함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_columns = ['workclass', 'occupation', 'native_country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Private'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#최빈값 가져오기\n",
    "# test['workclass'].mode()\n",
    "test['workclass'].mode()[0] # private 가 빈도수가 가장 높음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11       ?\n",
       "30       ?\n",
       "34       ?\n",
       "66       ?\n",
       "67       ?\n",
       "        ..\n",
       "26009    ?\n",
       "26010    ?\n",
       "26012    ?\n",
       "26046    ?\n",
       "26048    ?\n",
       "Name: workclass, Length: 1502, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_train.loc[train['workclass'] == '?','workclass'] # 두 번쨰 인자로 열이름을 주면 해당 열에 대한 시리즈 데이터\n",
    "# 두 번쨰 인자로 열이름을 안 넣어주면 데이터프레임 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "26044    0\n",
       "26045    0\n",
       "26046    0\n",
       "26047    0\n",
       "26048    0\n",
       "Name: capital_gain, Length: 26049, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_train['capital_gain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#최빈값 대치\n",
    "for col in na_columns:\n",
    "    tmp_train.loc[train[col] == '?',col] = train[col].mode()[0]\n",
    "    tmp_test.loc[test[col] == '?',col] = test[col].mode()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log 변환\n",
    "\n",
    "capital_gain 변수와 capital_loss 변수의 분포가 한쪽으로 치우친 형태이므로 Log 변환을 통해 분포의 형태를 조정해주겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd2164926d0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp_train['capital_gain'].plot.hist()\n",
    "# 왼쪽으로 너무 편향되어있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd216b78350>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#map 함수를 통해 자연로그 적용\n",
    "tmp_train['log_capital_gain'] = train['capital_gain'].map(lambda x : np.log(x) if x != 0 else 0)\n",
    "tmp_test['log_capital_gain'] = test['capital_gain'].map(lambda x : np.log(x) if x != 0 else 0)\n",
    "\n",
    "tmp_train['log_capital_gain'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd216984650>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 똑같이 capital_loss 에 적용\n",
    "train['capital_loss'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd216a0f090>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp_train['log_capital_loss'] = train['capital_loss'].map(lambda x : np.log(x) if x != 0 else 0)\n",
    "tmp_test['log_capital_loss'] = test['capital_loss'].map(lambda x : np.log(x) if x != 0 else 0)\n",
    "\n",
    "tmp_train['log_capital_loss'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로그 취하기전 데이터는 지워주기\n",
    "tmp_train = tmp_train.drop(columns=['capital_loss', 'capital_gain'])\n",
    "tmp_test  = tmp_test.drop(columns=['capital_loss', 'capital_gain'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 5) 데이터 쪼개기\n",
    "##### 1. Train, Valid, Test Set\n",
    "* Train Data : 모델을 학습하는데 사용하는 데이터 (모델이 알고 있는 학습할 데이터, 과거 데이터)\n",
    "* Valid Data : 학습한 모델의 성능을 검증하는 데이터 (모델이 모르는 학습하지 않을 데이터, 모델 검증에 사용하는 데이터, 과거 데이터)\n",
    "* Test Data : 학습한 모델로 예측할 데이터 (모델이 모르는 예측할 데이터, 미래 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tmp_train, tmp_valid, y_train, y_valid = train_test_split(tmp_train, label, \n",
    "                                                          test_size=0.3,\n",
    "                                                          random_state=2020,\n",
    "                                                          shuffle=True,\n",
    "                                                          stratify=label)\n",
    "# test_size = 0.3 -> 테스트데이터는 0.3 비율로 나누겠다.\n",
    "# random_state = 랜덤 씨드 값\n",
    "# shuffle = True 섞은 다음 나누겠다.\n",
    "# stratify = label  훈련 테스트 데이터들이 원본의 클래스의 비율과 같은 비율을 가지도록 할 것인지 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스 초기화\n",
    "# 데이터를 나눌 경우 인덱스가 뒤죽박죽 섞이게 된다.\n",
    "tmp_train = tmp_train.reset_index(drop=True) # drop = True 를 하면 또다른 인덱스 생성 x 필수로해줘야함\n",
    "tmp_valid = tmp_valid.reset_index(drop=True)\n",
    "tmp_test = tmp_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 스케일링\n",
    "\n",
    "Scikit-learn 라이브러리에 있는 Standard Scaler를 사용해서 수치형 변수들의 표준화를 진행하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "범주형 변수: \n",
      "['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country']\n",
      "\n",
      " 수치형 변수 : \n",
      "['age', 'fnlwgt', 'education_num', 'hours_per_week', 'log_capital_gain', 'log_capital_loss']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 먼저 범주형 변수와 수치형 변수를 나눠줘야 함.\n",
    "cat_columns = [c for c , t in zip(tmp_train.dtypes.index, tmp_train.dtypes) if t == 'O']\n",
    "# 오브젝트 타입으로 되어있는 칼럼이름들만 저장해라\n",
    "num_columns = [c for c in tmp_train.columns if c not in cat_columns]\n",
    "# 위에 조건이 아닌 것들은 다 수치형 타입\n",
    "\n",
    "print('범주형 변수: \\n{}\\n\\n 수치형 변수 : \\n{}\\n'.format(cat_columns,num_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "tmp_train[num_columns] = scaler.fit_transform(tmp_train[num_columns])\n",
    "# 테스트 데이터의 대한 특징들을 모델이 기억해야 함으로 fit 과 transform 을 같이했다.\n",
    "tmp_valid[num_columns] = scaler.transform(tmp_valid[num_columns])\n",
    "tmp_test[num_columns]  = scaler.transform(tmp_test[num_columns])\n",
    "# 나머지는 trainsform 만 해줘야함!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education_num</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>log_capital_gain</th>\n",
       "      <th>log_capital_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.823400e+04</td>\n",
       "      <td>1.823400e+04</td>\n",
       "      <td>1.823400e+04</td>\n",
       "      <td>1.823400e+04</td>\n",
       "      <td>1.823400e+04</td>\n",
       "      <td>1.823400e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.353712e-16</td>\n",
       "      <td>-3.069949e-17</td>\n",
       "      <td>2.664255e-16</td>\n",
       "      <td>4.398370e-16</td>\n",
       "      <td>-1.446012e-15</td>\n",
       "      <td>3.109830e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000027e+00</td>\n",
       "      <td>1.000027e+00</td>\n",
       "      <td>1.000027e+00</td>\n",
       "      <td>1.000027e+00</td>\n",
       "      <td>1.000027e+00</td>\n",
       "      <td>1.000027e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.575121e+00</td>\n",
       "      <td>-1.661651e+00</td>\n",
       "      <td>-3.549168e+00</td>\n",
       "      <td>-3.175259e+00</td>\n",
       "      <td>-3.032959e-01</td>\n",
       "      <td>-2.209828e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.441270e-01</td>\n",
       "      <td>-6.773644e-01</td>\n",
       "      <td>-4.287495e-01</td>\n",
       "      <td>-3.725226e-02</td>\n",
       "      <td>-3.032959e-01</td>\n",
       "      <td>-2.209828e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.131329e-01</td>\n",
       "      <td>-1.055421e-01</td>\n",
       "      <td>-3.869719e-02</td>\n",
       "      <td>-3.725226e-02</td>\n",
       "      <td>-3.032959e-01</td>\n",
       "      <td>-2.209828e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.909606e-01</td>\n",
       "      <td>4.466872e-01</td>\n",
       "      <td>1.131460e+00</td>\n",
       "      <td>3.650563e-01</td>\n",
       "      <td>-3.032959e-01</td>\n",
       "      <td>-2.209828e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.761136e+00</td>\n",
       "      <td>1.188097e+01</td>\n",
       "      <td>2.301616e+00</td>\n",
       "      <td>4.709988e+00</td>\n",
       "      <td>4.326449e+00</td>\n",
       "      <td>5.071417e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  education_num  hours_per_week  \\\n",
       "count  1.823400e+04  1.823400e+04   1.823400e+04    1.823400e+04   \n",
       "mean  -1.353712e-16 -3.069949e-17   2.664255e-16    4.398370e-16   \n",
       "std    1.000027e+00  1.000027e+00   1.000027e+00    1.000027e+00   \n",
       "min   -1.575121e+00 -1.661651e+00  -3.549168e+00   -3.175259e+00   \n",
       "25%   -8.441270e-01 -6.773644e-01  -4.287495e-01   -3.725226e-02   \n",
       "50%   -1.131329e-01 -1.055421e-01  -3.869719e-02   -3.725226e-02   \n",
       "75%    6.909606e-01  4.466872e-01   1.131460e+00    3.650563e-01   \n",
       "max    3.761136e+00  1.188097e+01   2.301616e+00    4.709988e+00   \n",
       "\n",
       "       log_capital_gain  log_capital_loss  \n",
       "count      1.823400e+04      1.823400e+04  \n",
       "mean      -1.446012e-15      3.109830e-17  \n",
       "std        1.000027e+00      1.000027e+00  \n",
       "min       -3.032959e-01     -2.209828e-01  \n",
       "25%       -3.032959e-01     -2.209828e-01  \n",
       "50%       -3.032959e-01     -2.209828e-01  \n",
       "75%       -3.032959e-01     -2.209828e-01  \n",
       "max        4.326449e+00      5.071417e+00  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_train.describe()\n",
    "# std 스케일러 이기 떄문에 평균이 0이고 분산이 1인지 확인해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education_num</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>log_capital_gain</th>\n",
       "      <th>log_capital_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7815.000000</td>\n",
       "      <td>7815.000000</td>\n",
       "      <td>7815.000000</td>\n",
       "      <td>7815.000000</td>\n",
       "      <td>7815.000000</td>\n",
       "      <td>7815.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.005257</td>\n",
       "      <td>-0.011081</td>\n",
       "      <td>-0.014091</td>\n",
       "      <td>-0.005325</td>\n",
       "      <td>-0.014643</td>\n",
       "      <td>0.006928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.997915</td>\n",
       "      <td>0.984603</td>\n",
       "      <td>1.004929</td>\n",
       "      <td>0.982061</td>\n",
       "      <td>0.975637</td>\n",
       "      <td>1.014457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.575121</td>\n",
       "      <td>-1.614138</td>\n",
       "      <td>-3.549168</td>\n",
       "      <td>-3.175259</td>\n",
       "      <td>-0.303296</td>\n",
       "      <td>-0.220983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.771028</td>\n",
       "      <td>-0.686258</td>\n",
       "      <td>-0.428749</td>\n",
       "      <td>-0.037252</td>\n",
       "      <td>-0.303296</td>\n",
       "      <td>-0.220983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.113133</td>\n",
       "      <td>-0.119802</td>\n",
       "      <td>-0.038697</td>\n",
       "      <td>-0.037252</td>\n",
       "      <td>-0.303296</td>\n",
       "      <td>-0.220983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.690961</td>\n",
       "      <td>0.431563</td>\n",
       "      <td>0.741407</td>\n",
       "      <td>0.365056</td>\n",
       "      <td>-0.303296</td>\n",
       "      <td>-0.220983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.761136</td>\n",
       "      <td>12.155926</td>\n",
       "      <td>2.301616</td>\n",
       "      <td>4.709988</td>\n",
       "      <td>4.326449</td>\n",
       "      <td>4.980164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age       fnlwgt  education_num  hours_per_week  \\\n",
       "count  7815.000000  7815.000000    7815.000000     7815.000000   \n",
       "mean      0.005257    -0.011081      -0.014091       -0.005325   \n",
       "std       0.997915     0.984603       1.004929        0.982061   \n",
       "min      -1.575121    -1.614138      -3.549168       -3.175259   \n",
       "25%      -0.771028    -0.686258      -0.428749       -0.037252   \n",
       "50%      -0.113133    -0.119802      -0.038697       -0.037252   \n",
       "75%       0.690961     0.431563       0.741407        0.365056   \n",
       "max       3.761136    12.155926       2.301616        4.709988   \n",
       "\n",
       "       log_capital_gain  log_capital_loss  \n",
       "count       7815.000000       7815.000000  \n",
       "mean          -0.014643          0.006928  \n",
       "std            0.975637          1.014457  \n",
       "min           -0.303296         -0.220983  \n",
       "25%           -0.303296         -0.220983  \n",
       "50%           -0.303296         -0.220983  \n",
       "75%           -0.303296         -0.220983  \n",
       "max            4.326449          4.980164  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_valid.describe()\n",
    "# train 데이터로 fitting 했기 떄문에 valid 는 평균이 0 이 아니고 분산도 1이 아니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인코딩\n",
    "\n",
    "범주형 변수를 수치형 변수로 인코딩 하겠습니다. 범주형 변수에는 Onehot Encoding을 적용합니다. <br>\n",
    "범주형 변수가 순서형 데이터로 크기가 의미있는 경우 라벨인코더를 사용해도 괜찮음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categories='auto', drop=None, dtype=<class 'numpy.float64'>,\n",
       "              handle_unknown='error', sparse=False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "tmp_all = pd.concat([tmp_train, tmp_valid , tmp_test])\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "ohe.fit(tmp_all[cat_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ohe.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_columns = []\n",
    "for lst in ohe.categories_:\n",
    "    ohe_columns += lst.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_cat = pd.DataFrame(ohe.transform(tmp_train[cat_columns]), columns=ohe_columns)\n",
    "new_valid_cat = pd.DataFrame(ohe.transform(tmp_valid[cat_columns]), columns=ohe_columns)\n",
    "new_test_cat  = pd.DataFrame(ohe.transform(tmp_test[cat_columns]), columns=ohe_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 여기서 카테고리 데이터는 왜 합친다음에 인코딩을 진행하나?\n",
    "#### ( 수치형 데이터는 스케일링 할때 train 데이터만 스케일링 했는데)\n",
    "\n",
    "이유는 카테고리컬 데이터는 train 데이터에는 없으나 test 혹은 valid 데이터에만 있는 범주데이터가 있을 수 있으므로<br>\n",
    "concat() 함수로 합쳐준 후 fitting 하고 다시 나눠줘야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Federal-gov</th>\n",
       "      <th>Local-gov</th>\n",
       "      <th>Never-worked</th>\n",
       "      <th>Private</th>\n",
       "      <th>Self-emp-inc</th>\n",
       "      <th>Self-emp-not-inc</th>\n",
       "      <th>State-gov</th>\n",
       "      <th>Without-pay</th>\n",
       "      <th>10th</th>\n",
       "      <th>11th</th>\n",
       "      <th>...</th>\n",
       "      <th>Portugal</th>\n",
       "      <th>Puerto-Rico</th>\n",
       "      <th>Scotland</th>\n",
       "      <th>South</th>\n",
       "      <th>Taiwan</th>\n",
       "      <th>Thailand</th>\n",
       "      <th>Trinadad&amp;Tobago</th>\n",
       "      <th>United-States</th>\n",
       "      <th>Vietnam</th>\n",
       "      <th>Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Federal-gov  Local-gov  Never-worked  Private  Self-emp-inc  \\\n",
       "0          0.0        0.0           0.0      1.0           0.0   \n",
       "1          0.0        0.0           0.0      1.0           0.0   \n",
       "2          0.0        0.0           0.0      1.0           0.0   \n",
       "3          0.0        0.0           0.0      1.0           0.0   \n",
       "4          0.0        0.0           0.0      1.0           0.0   \n",
       "\n",
       "   Self-emp-not-inc  State-gov  Without-pay  10th  11th  ...  Portugal  \\\n",
       "0               0.0        0.0          0.0   0.0   0.0  ...       0.0   \n",
       "1               0.0        0.0          0.0   0.0   0.0  ...       0.0   \n",
       "2               0.0        0.0          0.0   0.0   0.0  ...       0.0   \n",
       "3               0.0        0.0          0.0   0.0   0.0  ...       0.0   \n",
       "4               0.0        0.0          0.0   0.0   0.0  ...       0.0   \n",
       "\n",
       "   Puerto-Rico  Scotland  South  Taiwan  Thailand  Trinadad&Tobago  \\\n",
       "0          0.0       0.0    0.0     0.0       0.0              0.0   \n",
       "1          0.0       0.0    0.0     0.0       0.0              0.0   \n",
       "2          0.0       0.0    0.0     0.0       0.0              0.0   \n",
       "3          0.0       0.0    0.0     0.0       0.0              0.0   \n",
       "4          0.0       0.0    0.0     0.0       0.0              0.0   \n",
       "\n",
       "   United-States  Vietnam  Yugoslavia  \n",
       "0            1.0      0.0         0.0  \n",
       "1            1.0      0.0         0.0  \n",
       "2            1.0      0.0         0.0  \n",
       "3            1.0      0.0         0.0  \n",
       "4            1.0      0.0         0.0  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['workclass',\n",
       " 'education',\n",
       " 'marital_status',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'native_country']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코딩된 카테고리 데이터를 뒤에 붙이고 원래있던 카테고리를 제거한다. \n",
    "tmp_train = pd.concat([tmp_train, new_train_cat], axis=1)\n",
    "tmp_valid = pd.concat([tmp_valid, new_valid_cat], axis=1)\n",
    "tmp_test = pd.concat([tmp_test, new_test_cat], axis=1)\n",
    "\n",
    "# 기존 범주형 변수 제거\n",
    "tmp_train = tmp_train.drop(columns=cat_columns)\n",
    "tmp_valid = tmp_valid.drop(columns=cat_columns)\n",
    "tmp_test = tmp_test.drop(columns=cat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education_num</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>log_capital_gain</th>\n",
       "      <th>log_capital_loss</th>\n",
       "      <th>Federal-gov</th>\n",
       "      <th>Local-gov</th>\n",
       "      <th>Never-worked</th>\n",
       "      <th>Private</th>\n",
       "      <th>...</th>\n",
       "      <th>Portugal</th>\n",
       "      <th>Puerto-Rico</th>\n",
       "      <th>Scotland</th>\n",
       "      <th>South</th>\n",
       "      <th>Taiwan</th>\n",
       "      <th>Thailand</th>\n",
       "      <th>Trinadad&amp;Tobago</th>\n",
       "      <th>United-States</th>\n",
       "      <th>Vietnam</th>\n",
       "      <th>Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.325464</td>\n",
       "      <td>2.763660</td>\n",
       "      <td>-0.038697</td>\n",
       "      <td>-0.198176</td>\n",
       "      <td>3.038414</td>\n",
       "      <td>-0.220983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.252364</td>\n",
       "      <td>-0.527452</td>\n",
       "      <td>-0.038697</td>\n",
       "      <td>-0.037252</td>\n",
       "      <td>-0.303296</td>\n",
       "      <td>-0.220983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.106165</td>\n",
       "      <td>-0.130971</td>\n",
       "      <td>-0.038697</td>\n",
       "      <td>-0.037252</td>\n",
       "      <td>-0.303296</td>\n",
       "      <td>-0.220983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.697928</td>\n",
       "      <td>0.321262</td>\n",
       "      <td>-0.038697</td>\n",
       "      <td>0.365056</td>\n",
       "      <td>-0.303296</td>\n",
       "      <td>-0.220983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.282723</td>\n",
       "      <td>-0.447108</td>\n",
       "      <td>-0.428749</td>\n",
       "      <td>-0.037252</td>\n",
       "      <td>-0.303296</td>\n",
       "      <td>-0.220983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age    fnlwgt  education_num  hours_per_week  log_capital_gain  \\\n",
       "0  0.325464  2.763660      -0.038697       -0.198176          3.038414   \n",
       "1  0.252364 -0.527452      -0.038697       -0.037252         -0.303296   \n",
       "2  0.106165 -0.130971      -0.038697       -0.037252         -0.303296   \n",
       "3 -0.697928  0.321262      -0.038697        0.365056         -0.303296   \n",
       "4 -1.282723 -0.447108      -0.428749       -0.037252         -0.303296   \n",
       "\n",
       "   log_capital_loss  Federal-gov  Local-gov  Never-worked  Private  ...  \\\n",
       "0         -0.220983          0.0        0.0           0.0      1.0  ...   \n",
       "1         -0.220983          0.0        0.0           0.0      1.0  ...   \n",
       "2         -0.220983          0.0        0.0           0.0      1.0  ...   \n",
       "3         -0.220983          0.0        0.0           0.0      1.0  ...   \n",
       "4         -0.220983          0.0        0.0           0.0      1.0  ...   \n",
       "\n",
       "   Portugal  Puerto-Rico  Scotland  South  Taiwan  Thailand  Trinadad&Tobago  \\\n",
       "0       0.0          0.0       0.0    0.0     0.0       0.0              0.0   \n",
       "1       0.0          0.0       0.0    0.0     0.0       0.0              0.0   \n",
       "2       0.0          0.0       0.0    0.0     0.0       0.0              0.0   \n",
       "3       0.0          0.0       0.0    0.0     0.0       0.0              0.0   \n",
       "4       0.0          0.0       0.0    0.0     0.0       0.0              0.0   \n",
       "\n",
       "   United-States  Vietnam  Yugoslavia  \n",
       "0            1.0      0.0         0.0  \n",
       "1            1.0      0.0         0.0  \n",
       "2            1.0      0.0         0.0  \n",
       "3            1.0      0.0         0.0  \n",
       "4            1.0      0.0         0.0  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_y_train = y_train\n",
    "tmp_y_valid = y_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Scikit-Learn 분류 모델 사용해보기\n",
    "Scikit-Learn의 기본 분류 모델을 사용해보겠습니다. <br>\n",
    "각 모델의 평가 메트릭은 대회 평가 메트릭인 f1_score를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 로지스틱 회귀 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1 Score: 0.8474728087012157\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(tmp_train, tmp_y_train)\n",
    "\n",
    "y_pred = lr.predict(tmp_valid)\n",
    "\n",
    "print(f\"Logistic Regression F1 Score: {f1_score(tmp_y_valid, y_pred, average='micro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 서포트 벡터 머신(rbf 커널)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine F1 Score: 0.8551503518873961\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "\n",
    "svc.fit(tmp_train, tmp_y_train)\n",
    "\n",
    "y_pred = svc.predict(tmp_valid)\n",
    "\n",
    "print(f\"Support Vector Machine F1 Score: {f1_score(tmp_y_valid, y_pred, average='micro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 랜덤 포레스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest F1 Score: 0.8547664747280871\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(tmp_train, tmp_y_train)\n",
    "\n",
    "y_pred = rf.predict(tmp_valid)\n",
    "\n",
    "print(f\"RandomForest F1 Score: {f1_score(tmp_y_valid, y_pred, average='micro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost F1 Score: 0.8628278950735765\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "# xgb = XGBClassifier(tree_method='gpu_hist') #gpu 사용\n",
    "\n",
    "xgb.fit(tmp_train, tmp_y_train)\n",
    "\n",
    "y_pred = xgb.predict(tmp_valid)\n",
    "\n",
    "print(f\"XGBoost F1 Score: {f1_score(tmp_y_valid, y_pred, average='micro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM F1 Score: 0.8701215611004478\n"
     ]
    }
   ],
   "source": [
    "lgb = LGBMClassifier()\n",
    "#lgb = LGBMClassifier(tree_method='gpu_hist') #gpu 사용\n",
    "lgb.fit(tmp_train, tmp_y_train)\n",
    "\n",
    "y_pred = lgb.predict(tmp_valid)\n",
    "\n",
    "print(f\"LightGBM F1 Score: {f1_score(tmp_y_valid, y_pred, average='micro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Fold Cross Vaildation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x_train, x_valid, x_test):\n",
    "    tmp_x_train = x_train.copy()\n",
    "    tmp_x_valid = x_valid.copy()\n",
    "    tmp_x_test  = x_test.copy()\n",
    "    \n",
    "    tmp_x_train = tmp_x_train.reset_index(drop=True)\n",
    "    tmp_x_valid = tmp_x_valid.reset_index(drop=True)\n",
    "    tmp_x_test  = tmp_x_test.reset_index(drop=True)\n",
    "    \n",
    "    for c in na_columns:\n",
    "        tmp_x_train.loc[tmp_x_train[c] == '?', c] = tmp_x_train[c].mode()[0]\n",
    "        tmp_x_valid.loc[tmp_x_valid[c] == '?', c] = tmp_x_valid[c].mode()[0]\n",
    "        tmp_x_test.loc[tmp_x_test[c]   == '?', c] = tmp_x_test[c].mode()[0]\n",
    "    \n",
    "    tmp_x_train['log_capital_loss'] = tmp_x_train['capital_loss'].map(lambda x : np.log(x) if x != 0 else 0)\n",
    "    tmp_x_valid['log_capital_loss'] = tmp_x_valid['capital_loss'].map(lambda x : np.log(x) if x != 0 else 0)\n",
    "    tmp_x_test['log_capital_loss'] = tmp_x_test['capital_loss'].map(lambda x : np.log(x) if x != 0 else 0)\n",
    "    \n",
    "    tmp_x_train['log_capital_gain'] = tmp_x_train['capital_gain'].map(lambda x : np.log(x) if x != 0 else 0)\n",
    "    tmp_x_valid['log_capital_gain'] = tmp_x_valid['capital_gain'].map(lambda x : np.log(x) if x != 0 else 0)\n",
    "    tmp_x_test['log_capital_gain'] = tmp_x_test['capital_gain'].map(lambda x : np.log(x) if x != 0 else 0)\n",
    "    \n",
    "    tmp_x_train = tmp_x_train.drop(columns=['capital_loss', 'capital_gain'])\n",
    "    tmp_x_valid = tmp_x_valid.drop(columns=['capital_loss', 'capital_gain'])\n",
    "    tmp_x_test  = tmp_x_test.drop(columns=['capital_loss', 'capital_gain'])\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    tmp_x_train[num_columns] = scaler.fit_transform(tmp_x_train[num_columns])\n",
    "    tmp_x_valid[num_columns] = scaler.transform(tmp_x_valid[num_columns])\n",
    "    tmp_x_test[num_columns]  = scaler.transform(tmp_x_test[num_columns])\n",
    "    \n",
    "    tmp_all = pd.concat([tmp_x_train, tmp_x_valid, tmp_x_test])\n",
    "\n",
    "    ohe = OneHotEncoder(sparse=False)\n",
    "    ohe.fit(tmp_all[cat_columns])\n",
    "    \n",
    "    ohe_columns = list()\n",
    "    for lst in ohe.categories_:\n",
    "        ohe_columns += lst.tolist()\n",
    "    \n",
    "    tmp_train_cat = pd.DataFrame(ohe.transform(tmp_x_train[cat_columns]), columns=ohe_columns)\n",
    "    tmp_valid_cat = pd.DataFrame(ohe.transform(tmp_x_valid[cat_columns]), columns=ohe_columns)\n",
    "    tmp_test_cat  = pd.DataFrame(ohe.transform(tmp_x_test[cat_columns]), columns=ohe_columns)\n",
    "    \n",
    "    tmp_x_train = pd.concat([tmp_x_train, tmp_train_cat], axis=1)\n",
    "    tmp_x_valid = pd.concat([tmp_x_valid, tmp_valid_cat], axis=1)\n",
    "    tmp_x_test = pd.concat([tmp_x_test, tmp_test_cat], axis=1)\n",
    "\n",
    "    tmp_x_train = tmp_x_train.drop(columns=cat_columns)\n",
    "    tmp_x_valid = tmp_x_valid.drop(columns=cat_columns)\n",
    "    tmp_x_test = tmp_x_test.drop(columns=cat_columns)\n",
    "    \n",
    "    return tmp_x_train.values, tmp_x_valid.values, tmp_x_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1-Score 를 계산해주는 함수\n",
    "def xgb_f1(y, t, threshold=0.5):\n",
    "    t = t.get_label()\n",
    "    y_bin = (y > threshold).astype(int) \n",
    "    return 'f1',f1_score(t, y_bin, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#StartifiedKFold - 클래스 비율의 맞춰서 비율이 일정하게 나눠준다.\n",
    "# K-Fold 는 클래스비율의 상관없이 나눈다.\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.157198\tvalidation_0-f1:0.842802\n",
      "Multiple eval metrics have been passed: 'validation_0-f1' will be used for early stopping.\n",
      "\n",
      "Will train until validation_0-f1 hasn't improved in 100 rounds.\n",
      "[99]\tvalidation_0-error:0.138388\tvalidation_0-f1:0.861612\n",
      "0 Fold, train f1_score : 0.84164, validation f1_score : 0.8428\n",
      "\n",
      "[0]\tvalidation_0-error:0.155854\tvalidation_0-f1:0.844146\n",
      "Multiple eval metrics have been passed: 'validation_0-f1' will be used for early stopping.\n",
      "\n",
      "Will train until validation_0-f1 hasn't improved in 100 rounds.\n",
      "[99]\tvalidation_0-error:0.136468\tvalidation_0-f1:0.863532\n",
      "1 Fold, train f1_score : 0.84134, validation f1_score : 0.8441\n",
      "\n",
      "[0]\tvalidation_0-error:0.162764\tvalidation_0-f1:0.837236\n",
      "Multiple eval metrics have been passed: 'validation_0-f1' will be used for early stopping.\n",
      "\n",
      "Will train until validation_0-f1 hasn't improved in 100 rounds.\n",
      "[99]\tvalidation_0-error:0.140499\tvalidation_0-f1:0.859501\n",
      "2 Fold, train f1_score : 0.84314, validation f1_score : 0.8372\n",
      "\n",
      "[0]\tvalidation_0-error:0.157965\tvalidation_0-f1:0.842035\n",
      "Multiple eval metrics have been passed: 'validation_0-f1' will be used for early stopping.\n",
      "\n",
      "Will train until validation_0-f1 hasn't improved in 100 rounds.\n",
      "[99]\tvalidation_0-error:0.13858\tvalidation_0-f1:0.86142\n",
      "3 Fold, train f1_score : 0.84054, validation f1_score : 0.8420\n",
      "\n",
      "[0]\tvalidation_0-error:0.159916\tvalidation_0-f1:0.840084\n",
      "Multiple eval metrics have been passed: 'validation_0-f1' will be used for early stopping.\n",
      "\n",
      "Will train until validation_0-f1 hasn't improved in 100 rounds.\n",
      "[99]\tvalidation_0-error:0.134767\tvalidation_0-f1:0.865233\n",
      "4 Fold, train f1_score : 0.84244, validation f1_score : 0.8401\n",
      "\n",
      "Cross Validation Score : 0.8413\n"
     ]
    }
   ],
   "source": [
    "val_scores = list()\n",
    "oof_pred = np.zeros((test.shape[0],))\n",
    "\n",
    "#skf.split 을 하면 인덱스만 준다. 그래서 iloc으로 처리해줘야한다.\n",
    "for i, (trn_idx, val_idx) in enumerate(skf.split(train, label)):\n",
    "    x_train, y_train = train.iloc[trn_idx, :], label[trn_idx]\n",
    "    x_valid, y_valid = train.iloc[val_idx, :], label[val_idx]\n",
    "    \n",
    "    # 전처리\n",
    "    x_train, x_valid, x_test = preprocess(x_train, x_valid, test)\n",
    "    \n",
    "    # 모델 정의\n",
    "    clf = XGBClassifier()\n",
    "    \n",
    "    # 모델 학습\n",
    "    clf.fit(x_train, y_train,\n",
    "            eval_set = [[x_valid, y_valid]], \n",
    "            eval_metric = xgb_f1,        \n",
    "            early_stopping_rounds = 100,\n",
    "            verbose = 100,  )\n",
    "\n",
    "    # 훈련, 검증 데이터 Log Loss 확인\n",
    "    trn_f1_score = f1_score(y_train, clf.predict(x_train), average='micro')\n",
    "    val_f1_score = f1_score(y_valid, clf.predict(x_valid), average='micro')\n",
    "    print('{} Fold, train f1_score : {:.4f}4, validation f1_score : {:.4f}\\n'.format(i, trn_f1_score, val_f1_score))\n",
    "    \n",
    "    val_scores.append(val_f1_score)\n",
    "    \n",
    "\n",
    "# 교차 검증 F1 Score 평균 계산하기\n",
    "print('Cross Validation Score : {:.4f}'.format(np.mean(val_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. OOF(Out-Of-Fold) 앙상블\n",
    "k-Fold를 활용해서 모델 검증 및 각 폴드의 결과를 앙상블하는 OOF 앙상블 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.157198\tvalidation_0-f1:0.842802\n",
      "Multiple eval metrics have been passed: 'validation_0-f1' will be used for early stopping.\n",
      "\n",
      "Will train until validation_0-f1 hasn't improved in 100 rounds.\n",
      "[99]\tvalidation_0-error:0.138388\tvalidation_0-f1:0.861612\n",
      "0 Fold, train f1_score : 0.84164, validation f1_score : 0.8428\n",
      "\n",
      "[0]\tvalidation_0-error:0.155854\tvalidation_0-f1:0.844146\n",
      "Multiple eval metrics have been passed: 'validation_0-f1' will be used for early stopping.\n",
      "\n",
      "Will train until validation_0-f1 hasn't improved in 100 rounds.\n",
      "[99]\tvalidation_0-error:0.136468\tvalidation_0-f1:0.863532\n",
      "1 Fold, train f1_score : 0.84134, validation f1_score : 0.8441\n",
      "\n",
      "[0]\tvalidation_0-error:0.162764\tvalidation_0-f1:0.837236\n",
      "Multiple eval metrics have been passed: 'validation_0-f1' will be used for early stopping.\n",
      "\n",
      "Will train until validation_0-f1 hasn't improved in 100 rounds.\n",
      "[99]\tvalidation_0-error:0.140499\tvalidation_0-f1:0.859501\n",
      "2 Fold, train f1_score : 0.84314, validation f1_score : 0.8372\n",
      "\n",
      "[0]\tvalidation_0-error:0.157965\tvalidation_0-f1:0.842035\n",
      "Multiple eval metrics have been passed: 'validation_0-f1' will be used for early stopping.\n",
      "\n",
      "Will train until validation_0-f1 hasn't improved in 100 rounds.\n",
      "[99]\tvalidation_0-error:0.13858\tvalidation_0-f1:0.86142\n",
      "3 Fold, train f1_score : 0.84054, validation f1_score : 0.8420\n",
      "\n",
      "[0]\tvalidation_0-error:0.159916\tvalidation_0-f1:0.840084\n",
      "Multiple eval metrics have been passed: 'validation_0-f1' will be used for early stopping.\n",
      "\n",
      "Will train until validation_0-f1 hasn't improved in 100 rounds.\n",
      "[99]\tvalidation_0-error:0.134767\tvalidation_0-f1:0.865233\n",
      "4 Fold, train f1_score : 0.84244, validation f1_score : 0.8401\n",
      "\n",
      "Cross Validation Score : 0.8413\n"
     ]
    }
   ],
   "source": [
    "val_scores = list()\n",
    "oof_pred = np.zeros((test.shape[0], ))\n",
    "\n",
    "for i, (trn_idx, val_idx) in enumerate(skf.split(train, label)):\n",
    "    x_train, y_train = train.iloc[trn_idx, :], label[trn_idx]\n",
    "    x_valid, y_valid = train.iloc[val_idx, :], label[val_idx]\n",
    "    \n",
    "    # 전처리\n",
    "    x_train, x_valid, x_test = preprocess(x_train, x_valid, test)\n",
    "    \n",
    "    # 모델 정의\n",
    "    clf = XGBClassifier()\n",
    "    \n",
    "    # 모델 학습\n",
    "    clf.fit(x_train, y_train,\n",
    "            eval_set = [[x_valid, y_valid]], \n",
    "            eval_metric = xgb_f1,        \n",
    "            early_stopping_rounds = 100,\n",
    "            verbose = 100,  )\n",
    "\n",
    "    # 훈련, 검증 데이터 F1 Score 확인\n",
    "    trn_f1_score = f1_score(y_train, clf.predict(x_train), average='micro')\n",
    "    val_f1_score = f1_score(y_valid, clf.predict(x_valid), average='micro')\n",
    "    print('{} Fold, train f1_score : {:.4f}4, validation f1_score : {:.4f}\\n'.format(i, trn_f1_score, val_f1_score))\n",
    "    \n",
    "    val_scores.append(val_f1_score)\n",
    "    \n",
    "    oof_pred += clf.predict_proba(x_test)[:, 1] / n_splits\n",
    "    \n",
    "\n",
    "# 교차 검증 F1 Score 평균 계산하기\n",
    "print('Cross Validation Score : {:.4f}'.format(np.mean(val_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Stacking 앙상블\n",
    "2 stage 앙상블인 Stacking 앙상블 입니다. Stacking 앙상블은 수십개의 1 stage 모델의 결과를 모아 2 stage 모델로 학습 후 결과를 내는 앙상블 방식입니다.\n",
    "\n",
    "#### 1) 1 stage 결과 모으기\n",
    "Stacking 앙상블을 진행할 1 stage 모델의 결과(train, test)를 모읍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_scores = list()\n",
    "\n",
    "new_x_train_list = [np.zeros((train.shape[0], 1)) for _ in range(4)]\n",
    "new_x_test_list  = [np.zeros((test.shape[0], 1)) for _ in range(4)]\n",
    "\n",
    "for i, (trn_idx, val_idx) in enumerate(skf.split(train, label)):\n",
    "    print(f\"Fold {i} Start\")\n",
    "    x_train, y_train = train.iloc[trn_idx, :], label[trn_idx]\n",
    "    x_valid, y_valid = train.iloc[val_idx, :], label[val_idx]\n",
    "    \n",
    "    # 전처리\n",
    "    x_train, x_valid, x_test = preprocess(x_train, x_valid, test)\n",
    "    \n",
    "    # 모델 정의\n",
    "    clfs = [LogisticRegression(), \n",
    "            RandomForestClassifier(), \n",
    "            XGBClassifier(tree_method='gpu_hist'), \n",
    "            LGBMClassifier(tree_method='gpu_hist')]\n",
    "    \n",
    "    for model_idx, clf in enumerate(clfs):\n",
    "        clf.fit(x_train, y_train)\n",
    "        \n",
    "        new_x_train_list[model_idx][val_idx, :] = clf.predict_proba(x_valid)[:, 1].reshape(-1, 1)\n",
    "        new_x_test_list[model_idx][:] += clf.predict_proba(x_test)[:, 1].reshape(-1, 1) / n_splitsㅠ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = pd.DataFrame(np.concatenate(new_x_train_list, axis=1), columns=None)\n",
    "new_label = label\n",
    "new_test = pd.DataFrame(np.concatenate(new_x_test_list, axis=1), columns=None)\n",
    "\n",
    "new_train.shape, new_label.shape, new_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 2 Stage Meta Model 학습\n",
    "new_train, new_test에 들어있는 변수는 모두 수치형 변수이므로 Standard Scaling만 진행하겠습니다.<br>\n",
    "새로 생성한 데이터 new_train, new_test 데이터를 가지고 2 Stage Meta Model을 학습하고 결과를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_scores = list()\n",
    "oof_pred = np.zeros((test.shape[0], ))\n",
    "\n",
    "for i, (trn_idx, val_idx) in enumerate(skf.split(new_train, new_label)):\n",
    "    x_train, y_train = new_train.iloc[trn_idx, :], new_label[trn_idx]\n",
    "    x_valid, y_valid = new_train.iloc[val_idx, :], new_label[val_idx]\n",
    "    \n",
    "    # 전처리\n",
    "    scaler = StandardScaler()\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_valid = scaler.transform(x_valid)\n",
    "    x_test  = scaler.transform(new_test)\n",
    "    \n",
    "    # 모델 정의\n",
    "    clf = XGBClassifier(tree_method='gpu_hist')\n",
    "    \n",
    "    # 모델 학습\n",
    "    clf.fit(x_train, y_train,\n",
    "            eval_set = [[x_valid, y_valid]], \n",
    "            eval_metric = xgb_f1,        \n",
    "            early_stopping_rounds = 100,\n",
    "            verbose = 100,  )\n",
    "\n",
    "    # 훈련, 검증 데이터 F1 Score 확인\n",
    "    trn_f1_score = f1_score(y_train, clf.predict(x_train), average='micro')\n",
    "    val_f1_score = f1_score(y_valid, clf.predict(x_valid), average='micro')\n",
    "    print('{} Fold, train f1_score : {:.4f}4, validation f1_score : {:.4f}\\n'.format(i, trn_f1_score, val_f1_score))\n",
    "    \n",
    "    val_scores.append(val_f1_score)\n",
    "    \n",
    "    oof_pred += clf.predict_proba(x_test)[:, 1] / n_splits\n",
    "    \n",
    "\n",
    "# 교차 검증 F1 Score 평균 계산하기\n",
    "print('Cross Validation Score : {:.4f}'.format(np.mean(val_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 결과 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv(\"/kaggle/input/kakr-4th-competition/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.loc[:, 'prediction'] = (oof_pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
